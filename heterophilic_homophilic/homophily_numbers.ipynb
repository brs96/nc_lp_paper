{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea54a76-d34d-4503-86fa-b72914873392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.datasets import CitationFull\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "from torch_geometric.datasets import HeterophilousGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc48d0-5c65-4234-a44f-4b9c293eeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_determinism(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cac21-c34c-4bac-8ba7-3702d16e1509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_data(data, mask, device):\n",
    "    s_data = HeteroData()\n",
    "    s_data['paper'].x = data.x\n",
    "    s_data['paper', 'cites', 'paper'].edge_index = data.edge_index\n",
    "    unique_classes = data.y.unique()\n",
    "    s_data['label'].x = torch.eye(len(unique_classes), dtype=torch.float32, device=device)\n",
    "    mask_indices = torch.nonzero(mask, as_tuple=False).flatten()\n",
    "    label_edges = torch.zeros((2, mask_indices.size(0)), dtype=torch.int64, device=device)\n",
    "    label_edges[0] = mask_indices\n",
    "    label_edges[1] = data.y[mask_indices]\n",
    "    s_data['paper', 'is', 'label'].edge_index = label_edges\n",
    "    return s_data\n",
    "\n",
    "def split_train_edges(data, split_ratio=0.3):\n",
    "    total_edges = data['paper', 'is', 'label'].edge_index.size(1)\n",
    "    num_msg_edges = int(total_edges * split_ratio)\n",
    "    perm = torch.randperm(total_edges)\n",
    "    msg_edges = perm[:num_msg_edges]\n",
    "    sup_edges = perm[num_msg_edges:]\n",
    "    msg_edge_index = data['paper', 'is', 'label'].edge_index[:, msg_edges]\n",
    "    sup_edge_index = data['paper', 'is', 'label'].edge_index[:, sup_edges]\n",
    "    return msg_edge_index, sup_edge_index\n",
    "\n",
    "def prepare_lp_data(data, train_mask, val_mask, test_mask, device):\n",
    "    train_data_LP = sub_data(data, train_mask, device)\n",
    "    val_data_LP = sub_data(data, val_mask, device)\n",
    "    test_data_LP = sub_data(data, test_mask, device)\n",
    "    msg_edge_index, sup_edge_index = split_train_edges(train_data_LP)\n",
    "\n",
    "    train_data_LP['paper', 'is', 'label'].edge_index = msg_edge_index\n",
    "    train_data_LP['paper', 'is', 'label'].edge_label_index = sup_edge_index\n",
    "    train_data_LP['paper', 'is', 'label'].edge_label = torch.tensor(np.ones((sup_edge_index.size(1))))\n",
    "\n",
    "    val_data_LP['paper', 'is', 'label'].edge_label_index = val_data_LP['paper', 'is', 'label'].edge_index\n",
    "    val_data_LP['paper', 'is', 'label'].edge_index = torch.cat((msg_edge_index, sup_edge_index), 1)\n",
    "    val_data_LP['paper', 'is', 'label'].edge_label = torch.tensor(np.ones((val_data_LP['paper', 'is', 'label'].edge_label_index.size(1))))\n",
    "\n",
    "    test_data_LP['paper', 'is', 'label'].edge_label_index = test_data_LP['paper', 'is', 'label'].edge_index\n",
    "    test_data_LP['paper', 'is', 'label'].edge_index = torch.cat(\n",
    "        (msg_edge_index, sup_edge_index, val_data_LP['paper', 'is', 'label'].edge_label_index), 1\n",
    "    )\n",
    "    test_data_LP['paper', 'is', 'label'].edge_label = torch.tensor(\n",
    "        np.ones((test_data_LP['paper', 'is', 'label'].edge_label_index.size(1)))\n",
    "    )\n",
    "\n",
    "    train_data_LP = T.ToUndirected()(train_data_LP)\n",
    "    val_data_LP = T.ToUndirected()(val_data_LP)\n",
    "    test_data_LP = T.ToUndirected()(test_data_LP)\n",
    "\n",
    "    return train_data_LP, val_data_LP, test_data_LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cad796-f0d7-4149-899e-1c680c316303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import degree, to_undirected\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "\n",
    "def get_n_hop_sizes(graph_data, n_hop, input_nodes=None):\n",
    "    if input_nodes is None:\n",
    "        input_nodes = torch.arange(graph_data.num_nodes)\n",
    "    loader = NeighborLoader(\n",
    "        graph_data,\n",
    "        num_neighbors=[-1] * n_hop,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        input_nodes=input_nodes\n",
    "    )\n",
    "    sizes = []\n",
    "    hp_numbers = []\n",
    "    for batch in loader:\n",
    "        sizes.append(batch.num_nodes - 1)  # subtract the root node itself\n",
    "        root = batch.n_id[0]\n",
    "        num_same_class = 0\n",
    "        num_label_neighbors = 0\n",
    "        for i in range(batch.num_nodes-1):\n",
    "            neighbor_id = batch.n_id[i+1]\n",
    "            root_class = -1\n",
    "            if root<len(og_data.y):\n",
    "                root_class = og_data.y[root]\n",
    "            if neighbor_id<len(og_data.y):   \n",
    "                if og_data.y[neighbor_id] == root_class :\n",
    "                    num_same_class += 1\n",
    "            else:\n",
    "                num_label_neighbors += 1\n",
    "        \n",
    "        hp_numbers.append(num_same_class/(batch.num_nodes-1-num_label_neighbors))\n",
    "        \n",
    "    return torch.tensor(sizes), torch.tensor(hp_numbers)\n",
    "    \n",
    "def graph_stats(new_edges, new_edges_rev, data):    \n",
    "    # ORIGINAL GRAPH\n",
    "    \n",
    "    # metrics for the original graph (before rewiring)\n",
    "    num_paper_original = data.num_nodes\n",
    "    original_edge_index = data.edge_index\n",
    "    \n",
    "    #original_degrees = degree(original_edge_index[0], num_nodes=num_paper_original)\n",
    "    original_1hop, original_hp_1hop= get_n_hop_sizes(data, n_hop=1)\n",
    "    original_2hop, original_hp_2hop = get_n_hop_sizes(data, n_hop=2)\n",
    "    original_3hop, original_hp_3hop = get_n_hop_sizes(data, n_hop=3)\n",
    "    \n",
    "    \n",
    "    # reindex label nodes\n",
    "    new_edges[1] += num_paper_original  # Shift label indices by the number of paper nodes!!\n",
    "    new_edges_rev[0] += num_paper_original\n",
    "    # combine edges\n",
    "    combined_edge_index = torch.cat([original_edge_index, new_edges, new_edges_rev], dim=1)\n",
    "    \n",
    "    # calculate NEW total number of nodes\n",
    "    N_total = num_paper_original + num_classes\n",
    "    \n",
    "    # turn into homogeneous graph\n",
    "    homo_data = Data(edge_index=combined_edge_index, num_nodes=N_total)\n",
    "    \n",
    "    # metrics for the rewired graph (link prediction)\n",
    "    rewired_degrees = degree(homo_data.edge_index[0], num_nodes=N_total)\n",
    "    rewired_2hop, rewired_hp_2hop = get_n_hop_sizes(homo_data, n_hop=2)\n",
    "    rewired_3hop, rewired_hp_3hop = get_n_hop_sizes(homo_data, n_hop=3)\n",
    "    \n",
    "    # results\n",
    "    original_data = {\n",
    "        \"Node Index\": torch.arange(num_paper_original).numpy(),\n",
    "        \"Original 1-hop\": original_1hop.numpy(),\n",
    "        \"Original 2-hop\": original_2hop.numpy(),\n",
    "        \"Original 3-hop\": original_3hop.numpy(),\n",
    "        \"Original 1-hop HP\": original_hp_1hop.numpy(),\n",
    "        \"Original 2-hop HP\": original_hp_2hop.numpy(),\n",
    "        \"Original 3-hop HP\": original_hp_3hop.numpy(),\n",
    "    }\n",
    "    # rewired metrics apply to all nodes\n",
    "    rewired_data = {\n",
    "        \"Node Index\": torch.arange(N_total).numpy(),\n",
    "        \"Rewired 1-hop\": rewired_degrees.numpy(),\n",
    "        \"Rewired 2-hop\": rewired_2hop.numpy(),\n",
    "        \"Rewired 3-hop\": rewired_3hop.numpy(),\n",
    "        \"Rewired 2-hop HP\": rewired_hp_2hop.numpy(),\n",
    "        \"Rewired 3-hop HP\": rewired_hp_3hop.numpy(),\n",
    "        \"Is Label Node\": [1 if i >= num_paper_original else 0 for i in range(N_total)],\n",
    "    }\n",
    "    \n",
    "    original_df = pd.DataFrame(original_data)\n",
    "    rewired_df = pd.DataFrame(rewired_data)\n",
    "    comparison_df = pd.merge(original_df, rewired_df, on=\"Node Index\", how=\"right\")\n",
    "    \n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'CiteSeer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a11bf-bd10-481c-9416-d2ccffd17762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset=None\n",
    "if ds == 'CiteSeer':\n",
    "    dataset = CitationFull(root='data/CitationFull', name='CiteSeer')\n",
    "elif ds == 'Cora_ML':\n",
    "    dataset = CitationFull(root='data/CitationFull', name='Cora_ML')\n",
    "elif ds == 'Chameleon':\n",
    "    dataset = WikipediaNetwork(root='data/chameleon', name='chameleon')\n",
    "elif ds == 'Roman_Empire':\n",
    "    dataset = HeterophilousGraphDataset(root='data/RomanEmpire', name='Roman-empire')\n",
    "elif ds == 'Squirrel':\n",
    "    dataset = WikipediaNetwork(root='data/squirrel', name='squirrel')\n",
    "elif ds == 'OGBN':\n",
    "    dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='../../data/ogbn_arxiv')\n",
    "else:\n",
    "    print(\"Invalid dataset name.\")\n",
    "og_data = dataset[0]\n",
    "print(og_data)\n",
    "del og_data.train_mask\n",
    "del og_data.val_mask\n",
    "del og_data.test_mask\n",
    "og_data = T.ToUndirected()(og_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a040a9-9525-48f3-9ac5-f6d2ddaa6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_determinism(1)\n",
    "transform = RandomNodeSplit(num_val=0.1, num_test=0.1)\n",
    "data = transform(og_data.clone())\n",
    "num_classes = data.y.max().item() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55109c60-1c1f-4bcd-8e86-7e9eeadb80d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_LP, val_data_LP, test_data_LP = prepare_lp_data(data, data.train_mask, data.val_mask, data.test_mask, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c21ab-7b0e-4092-bbd4-896892bae516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = graph_stats(train_data_LP['paper', 'is', 'label'].edge_index.clone(), train_data_LP['label', 'rev_is', 'paper'].edge_index.clone(), og_data.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f16f72-c859-49d1-ab96-b275dc982e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_means = df1.groupby(\"Is Label Node\")[[\"Original 1-hop\", \"Original 2-hop\", \"Original 3-hop\", \"Original 1-hop HP\", \"Original 2-hop HP\", \"Original 3-hop HP\", \"Rewired 1-hop\", \"Rewired 2-hop\", \"Rewired 3-hop\", \"Rewired 2-hop HP\", \"Rewired 3-hop HP\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b34a10-afea-4d85-829e-fe603ccdfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
